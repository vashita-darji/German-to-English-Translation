{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4507
        },
        "id": "oB2jhzu2C4D-",
        "outputId": "b0d517c6-39b9-4c5a-e621-c32b3eb38d64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting azureml-sdk\n",
            "  Downloading azureml_sdk-1.58.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting azureml-core~=1.58.0 (from azureml-sdk)\n",
            "  Downloading azureml_core-1.58.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting azureml-dataset-runtime~=1.58.0 (from azureml-dataset-runtime[fuse]~=1.58.0->azureml-sdk)\n",
            "  Downloading azureml_dataset_runtime-1.58.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting azureml-train-core~=1.58.0 (from azureml-sdk)\n",
            "  Downloading azureml_train_core-1.58.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting azureml-train-automl-client~=1.58.0 (from azureml-sdk)\n",
            "  Downloading azureml_train_automl_client-1.58.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting azureml-pipeline~=1.58.0 (from azureml-sdk)\n",
            "  Downloading azureml_pipeline-1.58.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from azureml-core~=1.58.0->azureml-sdk) (2024.2)\n",
            "Collecting backports.tempfile (from azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting pathspec<1.0.0 (from azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.19.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.58.0->azureml-sdk) (2.32.3)\n",
            "Collecting msal<2.0.0,>=1.15.0 (from azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading msal-1.31.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting msal-extensions<=2.0.0,>=0.3.0 (from azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading msal_extensions-1.2.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting knack<0.13.0 (from azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading knack-0.12.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting azure-core<2.0.0 (from azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading azure_core-1.32.0-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting pkginfo (from azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading pkginfo-1.11.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting argcomplete<4 (from azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading argcomplete-3.5.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting humanfriendly<11.0,>=4.7 (from azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting paramiko<4.0.0,>=2.0.8 (from azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading paramiko-3.5.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting azure-mgmt-resource<=24.0.0,>=15.0.0 (from azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading azure_mgmt_resource-23.2.0-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting azure-mgmt-containerregistry<11,>=8.2.0 (from azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading azure_mgmt_containerregistry-10.3.0-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting azure-mgmt-storage<=22.0.0,>=16.0.0 (from azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading azure_mgmt_storage-21.2.1-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting azure-mgmt-keyvault<11.0.0,>=0.40.0 (from azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading azure_mgmt_keyvault-10.3.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting azure-mgmt-authorization<5,>=0.40.0 (from azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading azure_mgmt_authorization-4.0.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting azure-mgmt-network<=28.0.0 (from azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading azure_mgmt_network-28.0.0-py3-none-any.whl.metadata (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-graphrbac<1.0.0,>=0.40.0 (from azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading azure_graphrbac-0.61.2-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting azure-common<2.0.0,>=1.1.12 (from azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting msrest<=0.7.1,>=0.5.1 (from azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading msrest-0.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting msrestazure<=0.7,>=0.4.33 (from azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading msrestazure-0.6.4.post1-py2.py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: urllib3<3.0.0,>1.26.17 in /usr/local/lib/python3.10/dist-packages (from azureml-core~=1.58.0->azureml-sdk) (2.2.3)\n",
            "Requirement already satisfied: packaging<=25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from azureml-core~=1.58.0->azureml-sdk) (24.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from azureml-core~=1.58.0->azureml-sdk) (2.8.2)\n",
            "Collecting ndg-httpsclient<=0.5.1 (from azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: SecretStorage<4.0.0 in /usr/lib/python3/dist-packages (from azureml-core~=1.58.0->azureml-sdk) (3.3.1)\n",
            "Requirement already satisfied: jsonpickle<4.0.0 in /usr/local/lib/python3.10/dist-packages (from azureml-core~=1.58.0->azureml-sdk) (3.4.2)\n",
            "Collecting contextlib2<22.0.0 (from azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting docker<8.0.0 (from azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: PyJWT<3.0.0 in /usr/local/lib/python3.10/dist-packages (from azureml-core~=1.58.0->azureml-sdk) (2.9.0)\n",
            "Collecting adal<=1.2.7,>=1.2.0 (from azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading adal-1.2.7-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pyopenssl<25.0.0 in /usr/local/lib/python3.10/dist-packages (from azureml-core~=1.58.0->azureml-sdk) (24.2.1)\n",
            "Collecting jmespath<2.0.0 (from azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting azureml-dataprep<5.2.0a,>=5.1.0a (from azureml-dataset-runtime~=1.58.0->azureml-dataset-runtime[fuse]~=1.58.0->azureml-sdk)\n",
            "  Downloading azureml_dataprep-5.1.6-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: pyarrow>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from azureml-dataset-runtime~=1.58.0->azureml-dataset-runtime[fuse]~=1.58.0->azureml-sdk) (17.0.0)\n",
            "Collecting numpy!=1.19.3,<1.24 (from azureml-dataset-runtime~=1.58.0->azureml-dataset-runtime[fuse]~=1.58.0->azureml-sdk)\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting fusepy<4.0.0,>=3.0.1 (from azureml-dataset-runtime[fuse]~=1.58.0->azureml-sdk)\n",
            "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting azureml-pipeline-core~=1.58.0 (from azureml-pipeline~=1.58.0->azureml-sdk)\n",
            "  Downloading azureml_pipeline_core-1.58.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting azureml-pipeline-steps~=1.58.0 (from azureml-pipeline~=1.58.0->azureml-sdk)\n",
            "  Downloading azureml_pipeline_steps-1.58.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting azureml-automl-core~=1.58.0 (from azureml-train-automl-client~=1.58.0->azureml-sdk)\n",
            "  Downloading azureml_automl_core-1.58.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting azureml-telemetry~=1.58.0 (from azureml-train-automl-client~=1.58.0->azureml-sdk)\n",
            "  Downloading azureml_telemetry-1.58.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting azureml-train-restclients-hyperdrive~=1.58.0 (from azureml-train-core~=1.58.0->azureml-sdk)\n",
            "  Downloading azureml_train_restclients_hyperdrive-1.58.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: cryptography>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from adal<=1.2.7,>=1.2.0->azureml-core~=1.58.0->azureml-sdk) (43.0.3)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0->azureml-core~=1.58.0->azureml-sdk) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0->azureml-core~=1.58.0->azureml-sdk) (4.12.2)\n",
            "Collecting isodate<1.0.0,>=0.6.1 (from azure-mgmt-authorization<5,>=0.40.0->azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting azure-mgmt-core<2.0.0,>=1.3.2 (from azure-mgmt-authorization<5,>=0.40.0->azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading azure_mgmt_core-1.5.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting importlib-metadata<=8.2.0 (from azureml-automl-core~=1.58.0->azureml-train-automl-client~=1.58.0->azureml-sdk)\n",
            "  Downloading importlib_metadata-8.2.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting importlib-resources<=6.4.0 (from azureml-automl-core~=1.58.0->azureml-train-automl-client~=1.58.0->azureml-sdk)\n",
            "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting azureml-dataprep-native<42.0.0,>=41.0.0 (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.58.0->azureml-dataset-runtime[fuse]~=1.58.0->azureml-sdk)\n",
            "  Downloading azureml_dataprep_native-41.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting azureml-dataprep-rslex~=2.22.2dev0 (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.58.0->azureml-dataset-runtime[fuse]~=1.58.0->azureml-sdk)\n",
            "  Downloading azureml_dataprep_rslex-2.22.5-cp310-cp310-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting cloudpickle<3.0.0,>=1.1.0 (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.58.0->azureml-dataset-runtime[fuse]~=1.58.0->azureml-sdk)\n",
            "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting azure-identity>=1.7.0 (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.58.0->azureml-dataset-runtime[fuse]~=1.58.0->azureml-sdk)\n",
            "  Downloading azure_identity-1.19.0-py3-none-any.whl.metadata (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.58.0->azureml-dataset-runtime[fuse]~=1.58.0->azureml-sdk) (4.23.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.58.0->azureml-dataset-runtime[fuse]~=1.58.0->azureml-sdk) (6.0.2)\n",
            "Collecting applicationinsights (from azureml-telemetry~=1.58.0->azureml-train-automl-client~=1.58.0->azureml-sdk)\n",
            "  Downloading applicationinsights-0.11.10-py2.py3-none-any.whl.metadata (982 bytes)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from knack<0.13.0->azureml-core~=1.58.0->azureml-sdk) (2.18.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from knack<0.13.0->azureml-core~=1.58.0->azureml-sdk) (0.9.0)\n",
            "Collecting portalocker<3,>=1.4 (from msal-extensions<=2.0.0,>=0.3.0->azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from msrest<=0.7.1,>=0.5.1->azureml-core~=1.58.0->azureml-sdk) (2024.8.30)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from msrest<=0.7.1,>=0.5.1->azureml-core~=1.58.0->azureml-sdk) (1.3.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ndg-httpsclient<=0.5.1->azureml-core~=1.58.0->azureml-sdk) (0.6.1)\n",
            "Collecting bcrypt>=3.2 (from paramiko<4.0.0,>=2.0.8->azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting pynacl>=1.5 (from paramiko<4.0.0,>=2.0.8->azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.19.1->requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.58.0->azureml-sdk) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.19.1->requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.58.0->azureml-sdk) (3.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]<3.0.0,>=2.19.1->azureml-core~=1.58.0->azureml-sdk) (1.7.1)\n",
            "Collecting backports.weakref (from backports.tempfile->azureml-core~=1.58.0->azureml-sdk)\n",
            "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=1.1.0->adal<=1.2.7,>=1.2.0->azureml-core~=1.58.0->azureml-sdk) (1.17.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.2.0->azureml-automl-core~=1.58.0->azureml-train-automl-client~=1.58.0->azureml-sdk) (3.20.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.5.0->msrest<=0.7.1,>=0.5.1->azureml-core~=1.58.0->azureml-sdk) (3.2.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.58.0->azureml-dataset-runtime[fuse]~=1.58.0->azureml-sdk) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.58.0->azureml-dataset-runtime[fuse]~=1.58.0->azureml-sdk) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.58.0->azureml-dataset-runtime[fuse]~=1.58.0->azureml-sdk) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->azureml-dataprep<5.2.0a,>=5.1.0a->azureml-dataset-runtime~=1.58.0->azureml-dataset-runtime[fuse]~=1.58.0->azureml-sdk) (0.21.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=1.1.0->adal<=1.2.7,>=1.2.0->azureml-core~=1.58.0->azureml-sdk) (2.22)\n",
            "Downloading azureml_sdk-1.58.0-py3-none-any.whl (2.7 kB)\n",
            "Downloading azureml_core-1.58.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azureml_dataset_runtime-1.58.0-py3-none-any.whl (2.2 kB)\n",
            "Downloading azureml_pipeline-1.58.0-py3-none-any.whl (2.4 kB)\n",
            "Downloading azureml_train_automl_client-1.58.0-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azureml_train_core-1.58.0-py3-none-any.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading argcomplete-3.5.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
            "Downloading azure_core-1.32.0-py3-none-any.whl (198 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.9/198.9 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_graphrbac-0.61.2-py2.py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_mgmt_authorization-4.0.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_mgmt_containerregistry-10.3.0-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_mgmt_keyvault-10.3.1-py3-none-any.whl (901 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m901.4/901.4 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_mgmt_network-28.0.0-py3-none-any.whl (548 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.7/548.7 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_mgmt_resource-23.2.0-py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_mgmt_storage-21.2.1-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azureml_automl_core-1.58.0-py3-none-any.whl (249 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.6/249.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azureml_dataprep-5.1.6-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.4/252.4 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azureml_pipeline_core-1.58.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.7/313.7 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azureml_pipeline_steps-1.58.0-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azureml_telemetry-1.58.0-py3-none-any.whl (30 kB)\n",
            "Downloading azureml_train_restclients_hyperdrive-1.58.0-py3-none-any.whl (18 kB)\n",
            "Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading knack-0.12.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msal-1.31.0-py3-none-any.whl (113 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.1/113.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msal_extensions-1.2.0-py3-none-any.whl (19 kB)\n",
            "Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msrestazure-0.6.4.post1-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
            "Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading paramiko-3.5.0-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Downloading pkginfo-1.11.2-py3-none-any.whl (31 kB)\n",
            "Downloading azure_identity-1.19.0-py3-none-any.whl (187 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.6/187.6 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_mgmt_core-1.5.0-py3-none-any.whl (30 kB)\n",
            "Downloading azureml_dataprep_native-41.0.0-cp310-cp310-manylinux1_x86_64.whl (187 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.7/187.7 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azureml_dataprep_rslex-2.22.5-cp310-cp310-manylinux1_x86_64.whl (24.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.8/24.8 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
            "Downloading importlib_metadata-8.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
            "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading applicationinsights-0.11.10-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
            "Building wheels for collected packages: fusepy\n",
            "  Building wheel for fusepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10486 sha256=613293dc7d697ef3280cfbea0ad097bc1baa8cfe28729e8f2aa78aed2f396303\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/18/f6/f0d6be9d0435e2677ce5cc758e91da50053dce456a346f08c5\n",
            "Successfully built fusepy\n",
            "Installing collected packages: fusepy, backports.weakref, azureml-dataprep-rslex, azureml-dataprep-native, azure-common, applicationinsights, portalocker, pkginfo, pathspec, numpy, jmespath, isodate, importlib-resources, importlib-metadata, humanfriendly, contextlib2, cloudpickle, bcrypt, backports.tempfile, argcomplete, pynacl, knack, docker, azure-core, paramiko, msrest, azure-mgmt-core, adal, ndg-httpsclient, msrestazure, msal, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-network, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, msal-extensions, azureml-train-restclients-hyperdrive, azure-graphrbac, azureml-core, azure-identity, azureml-telemetry, azureml-pipeline-core, azureml-dataprep, azureml-train-core, azureml-dataset-runtime, azureml-automl-core, azureml-train-automl-client, azureml-pipeline-steps, azureml-pipeline, azureml-sdk\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib_resources 6.4.5\n",
            "    Uninstalling importlib_resources-6.4.5:\n",
            "      Successfully uninstalled importlib_resources-6.4.5\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.5.0\n",
            "    Uninstalling importlib_metadata-8.5.0:\n",
            "      Successfully uninstalled importlib_metadata-8.5.0\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 3.1.0\n",
            "    Uninstalling cloudpickle-3.1.0:\n",
            "      Successfully uninstalled cloudpickle-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.25.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "dask 2024.10.0 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2024.10.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed adal-1.2.7 applicationinsights-0.11.10 argcomplete-3.5.1 azure-common-1.1.28 azure-core-1.32.0 azure-graphrbac-0.61.2 azure-identity-1.19.0 azure-mgmt-authorization-4.0.0 azure-mgmt-containerregistry-10.3.0 azure-mgmt-core-1.5.0 azure-mgmt-keyvault-10.3.1 azure-mgmt-network-28.0.0 azure-mgmt-resource-23.2.0 azure-mgmt-storage-21.2.1 azureml-automl-core-1.58.0 azureml-core-1.58.0 azureml-dataprep-5.1.6 azureml-dataprep-native-41.0.0 azureml-dataprep-rslex-2.22.5 azureml-dataset-runtime-1.58.0 azureml-pipeline-1.58.0 azureml-pipeline-core-1.58.0 azureml-pipeline-steps-1.58.0 azureml-sdk-1.58.0 azureml-telemetry-1.58.0 azureml-train-automl-client-1.58.0 azureml-train-core-1.58.0 azureml-train-restclients-hyperdrive-1.58.0 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-4.2.0 cloudpickle-2.2.1 contextlib2-21.6.0 docker-7.1.0 fusepy-3.0.1 humanfriendly-10.0 importlib-metadata-8.2.0 importlib-resources-6.4.0 isodate-0.7.2 jmespath-1.0.1 knack-0.12.0 msal-1.31.0 msal-extensions-1.2.0 msrest-0.7.1 msrestazure-0.6.4.post1 ndg-httpsclient-0.5.1 numpy-1.23.5 paramiko-3.5.0 pathspec-0.12.1 pkginfo-1.11.2 portalocker-2.10.1 pynacl-1.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "backports",
                  "importlib_metadata",
                  "numpy"
                ]
              },
              "id": "06302364999344d9bde853fa90bcee9d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install azureml-sdk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\n",
        "from azureml.core.authentication import InteractiveLoginAuthentication\n",
        "\n",
        "# Use interactive login for Azure authentication (without service principal)\n",
        "auth = InteractiveLoginAuthentication()\n",
        "\n",
        "# Replace with your correct subscription, resource group, and workspace name\n",
        "ws = Workspace.get(name='travel_bot',\n",
        "                   subscription_id='6348e0cb-ef98-4058-9cf9-449e12a46b7a',\n",
        "                   resource_group='travel-bot',\n",
        "                   auth=auth)\n",
        "\n",
        "print(f'Workspace {ws.name} loaded successfully.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uOK20pgAD5wM",
        "outputId": "c34137f1-7692-4fca-9544-be2aa0892b42"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing interactive authentication. Please follow the instructions on the terminal.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:azureml._vendor.azure_cli_core.auth.identity:To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code A8LB34NBP to authenticate.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Interactive authentication successfully completed.\n",
            "Workspace travel_bot loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "# Register your models (replace with your actual file paths)\n",
        "encoder_model = Model.register(model_path=\"/content/scripted_encoder.pt\",\n",
        "                                model_name=\"scripted_encoder\",\n",
        "                                workspace=ws)\n",
        "\n",
        "decoder_model = Model.register(model_path=\"/content/scripted_decoder.pt\",\n",
        "                                model_name=\"scripted_decoder\",\n",
        "                                workspace=ws)\n",
        "\n",
        "config_model = Model.register(model_path=\"/content/model_config.pth\",\n",
        "                               model_name=\"model_config\",\n",
        "                               workspace=ws)\n",
        "\n",
        "print(\"Models registered successfully\")\n"
      ],
      "metadata": {
        "id": "NphddG4PEKSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Model, Environment\n",
        "from azureml.core.webservice import AciWebservice, Webservice\n",
        "from azureml.core.model import InferenceConfig\n",
        "\n",
        "\n",
        "# Load the registered models\n",
        "encoder_model = Model(ws, name='scripted_encoder')\n",
        "decoder_model = Model(ws, name='scripted_decoder')\n",
        "config_model = Model(ws, name='model_config3')\n",
        "\n",
        "print(\"Models loaded successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BvQGNco2EUCO",
        "outputId": "4c26ef34-0865-4448-b66f-9096107397c8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "\n",
        "# List all environments available in your workspace\n",
        "envs = Environment.list(workspace=ws)\n",
        "for env in envs:\n",
        "    print(env)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gM1t-EdDEbwF",
        "outputId": "87289fa4-a63e-4139-80b9-11d193a3fd9c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Define the inference configuration using the Azure managed PyTorch environment\n",
        " inference_config = InferenceConfig(\n",
        "    entry_script='score.py',\n",
        "    environment=Environment.get(ws, name='AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu')\n",
        " )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "# Create an environment using the env.yml file\n",
        "env = Environment.from_conda_specification(\n",
        "    name=\"my-custom-env\",\n",
        "    file_path=\"env.yml\"\n",
        ")\n",
        "\n",
        "# Define the inference configuration using your custom environment\n",
        "inference_config = InferenceConfig(\n",
        "    entry_script='score.py',\n",
        "    environment=env\n",
        ")\n",
        "'''"
      ],
      "metadata": {
        "id": "Ln57LRO1E-yd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "# Define ACI deployment configuration (adjust CPU and memory as needed)\n",
        "aci_config = AciWebservice.deploy_configuration(\n",
        "    cpu_cores=1,\n",
        "    memory_gb=2,\n",
        "    auth_enabled=True\n",
        ")\n",
        "\n",
        "# Deploy the service using ACI\n",
        "service_name = 'german-translate'\n",
        "service = Model.deploy(\n",
        "    workspace=ws,\n",
        "    name=service_name,\n",
        "    models=[encoder_model, decoder_model, config_model],\n",
        "    inference_config=inference_config,\n",
        "    deployment_config=aci_config\n",
        ")\n",
        "\n",
        "# Wait for deployment to complete\n",
        "service.wait_for_deployment(show_output=True)\n",
        "\n",
        "# Check the status\n",
        "print(f\"Service state: {service.state}\")\n",
        "print(f\"Scoring URI: {service.scoring_uri}\")\n",
        "print(f\"Swagger URI: {service.swagger_uri}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bIATARAWEr6O",
        "outputId": "a66fbbf2-161f-4795-e2b4-669bd092dc71"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-aaacff327aa2>:12: FutureWarning: azureml.core.model:\n",
            "To leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \n",
            "please refer to respective documentations \n",
            "https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\n",
            "https://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \n",
            "For more information on migration, see https://aka.ms/acimoemigration \n",
            "To disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n",
            "  service = Model.deploy(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2024-11-14 14:32:23+00:00 Creating Container Registry if not exists.\n",
            "2024-11-14 14:32:24+00:00 Use the existing image.\n",
            "2024-11-14 14:32:27+00:00 Submitting deployment to compute.\n",
            "2024-11-14 14:32:37+00:00 Checking the status of deployment german-translate..\n",
            "2024-11-14 14:39:55+00:00 Checking the status of inference endpoint german-translate.\n",
            "Succeeded\n",
            "ACI service creation operation finished, operation \"Succeeded\"\n",
            "Service state: Healthy\n",
            "Scoring URI: http://f0bcf2b8-a015-46f7-a2f2-ff3edf469c41.centralindia.azurecontainer.io/score\n",
            "Swagger URI: http://f0bcf2b8-a015-46f7-a2f2-ff3edf469c41.centralindia.azurecontainer.io/swagger.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.15.2 torch==2.0.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bW0kvbw_K5Sg",
        "outputId": "92da8e4d-7d86-4246-bc69-906b7c0ca660"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.15.2\n",
            "  Downloading torchtext-0.15.2-cp310-cp310-manylinux1_x86_64.whl.metadata (7.4 kB)\n",
            "Collecting torch==2.0.1\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2) (4.66.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2) (1.23.5)\n",
            "Collecting torchdata==0.6.1 (from torchtext==0.15.2)\n",
            "  Downloading torchdata-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.44.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1->torchtext==0.15.2) (2.2.3)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.30.5)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.2) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.2) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.2) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Downloading torchtext-0.15.2-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m848.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchdata, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.0+cu121\n",
            "    Uninstalling torch-2.5.0+cu121:\n",
            "      Successfully uninstalled torch-2.5.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.20.0+cu121 requires torch==2.5.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 torchdata-0.6.1 torchtext-0.15.2 triton-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# Constants for special tokens\n",
        "BOS_IDX = 2  # Beginning of Sentence\n",
        "EOS_IDX = 3  # End of Sentence\n",
        "PAD_IDX = 1  # Padding\n",
        "\n",
        "# Initialize global variables\n",
        "scripted_encoder = None\n",
        "scripted_decoder = None\n",
        "vocab_de = None\n",
        "vocab_en = None\n",
        "de_tokenizer = None\n",
        "en_tokenizer = None\n",
        "\n",
        "def load_model_and_config():\n",
        "    \"\"\"\n",
        "    Load the models and configuration data directly for Kaggle environment.\n",
        "    \"\"\"\n",
        "    global scripted_encoder, scripted_decoder, vocab_de, vocab_en, de_tokenizer, en_tokenizer\n",
        "\n",
        "    try:\n",
        "        # Load the TorchScript-ed encoder and decoder models independently\n",
        "        try:\n",
        "            scripted_encoder = torch.jit.load('/content/scripted_encoder.pt', map_location='cpu')\n",
        "            print(\"Encoder model loaded successfully.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading encoder model: {e}\")\n",
        "\n",
        "        try:\n",
        "            scripted_decoder = torch.jit.load('/content/scripted_decoder.pt', map_location='cpu')\n",
        "            print(\"Decoder model loaded successfully.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading decoder model: {e}\")\n",
        "\n",
        "        # Load the configuration data\n",
        "        try:\n",
        "            config_data = torch.load('/content/model_config3.pth', map_location='cpu')\n",
        "            print(\"Configuration data loaded successfully.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading configuration: {e}\")\n",
        "\n",
        "        # Extract vocabularies and tokenizers\n",
        "        if config_data:\n",
        "            vocab_de = config_data.get('vocab_de', None)\n",
        "            vocab_en = config_data.get('vocab_en', None)\n",
        "            de_tokenizer = config_data.get('de_tokenizer', None)\n",
        "            en_tokenizer = config_data.get('en_tokenizer', None)\n",
        "\n",
        "        # Initialize tokenizers if not provided\n",
        "        if de_tokenizer is None:\n",
        "            de_tokenizer = lambda sentence: sentence.split()  # Simple tokenizer for German (split by space)\n",
        "        if en_tokenizer is None:\n",
        "            en_tokenizer = lambda sentence: sentence.split()  # Simple tokenizer for English (split by space)\n",
        "\n",
        "        print(\"Model and configurations loaded successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during initialization: {str(e)}\")\n",
        "\n",
        "\n",
        "def translate_sentence(sentence, max_len=50, device='cpu'):\n",
        "    \"\"\"\n",
        "    Translate a sentence from German to English using the trained models.\n",
        "    \"\"\"\n",
        "    if scripted_encoder is None or scripted_decoder is None:\n",
        "        print(\"Error: Models are not loaded.\")\n",
        "        return None\n",
        "\n",
        "    scripted_encoder.eval()\n",
        "    scripted_decoder.eval()\n",
        "\n",
        "    # Tokenize and convert the input sentence in German to indices\n",
        "    tokens = de_tokenizer(sentence.rstrip(\"\\n\"))  # Tokenize the German sentence\n",
        "    src_ids = [vocab_de[token] for token in tokens] + [EOS_IDX]  # Convert tokens to indices and append <EOS>\n",
        "    src_tensor = torch.tensor(src_ids, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    # Pass the source sentence through the encoder\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, encoder_hidden = scripted_encoder(src_tensor)\n",
        "\n",
        "    tgt_ids = [BOS_IDX]  # Decoder input starts with <BOS>\n",
        "    tgt_tensor = torch.tensor([tgt_ids], dtype=torch.long).to(device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    output_tokens = []\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        with torch.no_grad():\n",
        "            y, decoder_hidden = scripted_decoder(tgt_tensor, decoder_hidden)\n",
        "            next_token_id = y.argmax(2).item()\n",
        "\n",
        "        if next_token_id == EOS_IDX:\n",
        "            break\n",
        "\n",
        "        output_tokens.append(next_token_id)\n",
        "        tgt_tensor = torch.tensor([[next_token_id]], dtype=torch.long).to(device)\n",
        "\n",
        "    # Convert indices back to English words using vocab_en.lookup_token\n",
        "    translated_sentence = ' '.join([vocab_en.lookup_token(token) for token in output_tokens])\n",
        "    return translated_sentence\n",
        "\n",
        "\n",
        "def score(input_data):\n",
        "    \"\"\"\n",
        "    This function handles the incoming requests for scoring or translation.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        input_json = json.loads(input_data)\n",
        "        sentence = input_json.get('sentence', '')\n",
        "\n",
        "        if not sentence:\n",
        "            return json.dumps({'error': 'No sentence provided'})\n",
        "\n",
        "        # Make sure models are loaded before running the translation\n",
        "        load_model_and_config()\n",
        "\n",
        "        translated_sentence = translate_sentence(sentence, device='cpu')\n",
        "        if translated_sentence:\n",
        "            return json.dumps({'translated_sentence': translated_sentence})\n",
        "        else:\n",
        "            return json.dumps({'error': 'Translation failed'})\n",
        "\n",
        "    except Exception as e:\n",
        "        return json.dumps({'error': str(e)})\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Example input for testing\n",
        "    input_data = json.dumps({\"sentence\": \"Guten Morgen\"})\n",
        "    print(score(input_data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FqPVGV8nK0Mb",
        "outputId": "c08f0b44-4b11-4620-aea2-2e06359edf31"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder model loaded successfully.\n",
            "Decoder model loaded successfully.\n",
            "Configuration data loaded successfully.\n",
            "Model and configurations loaded successfully!\n",
            "{\"translated_sentence\": \"orange group - haired woman watches in the middle of a white .\"}\n"
          ]
        }
      ]
    }
  ]
}